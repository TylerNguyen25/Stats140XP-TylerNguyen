<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.4.538">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Tyler Nguyen">
<meta name="dcterms.date" content="2024-03-04">

<title>Projects - Dogs and Cats Classification</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<script src="../../site_libs/quarto-html/quarto.js"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>


<link rel="stylesheet" href="../../styles.css">
</head>

<body class="nav-fixed fullcontent">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top quarto-banner">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a class="navbar-brand" href="../../index.html">
    <span class="navbar-title">Projects</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../about.html"> 
<span class="menu-text">Tyler Nguyen</span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
          <div class="quarto-navbar-tools">
</div>
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<header id="title-block-header" class="quarto-title-block default page-columns page-full">
  <div class="quarto-title-banner page-columns page-full">
    <div class="quarto-title column-body">
      <h1 class="title">Dogs and Cats Classification</h1>
                                <div class="quarto-categories">
                <div class="quarto-category">Keras</div>
                <div class="quarto-category">TensorFlow</div>
                <div class="quarto-category">Python</div>
                <div class="quarto-category">Neural Networks</div>
              </div>
                  </div>
  </div>
    
  
  <div class="quarto-title-meta">

      <div>
      <div class="quarto-title-meta-heading">Author</div>
      <div class="quarto-title-meta-contents">
               <p>Tyler Nguyen </p>
            </div>
    </div>
      
      <div>
      <div class="quarto-title-meta-heading">Published</div>
      <div class="quarto-title-meta-contents">
        <p class="date">March 4, 2024</p>
      </div>
    </div>
    
      
    </div>
    
  
  </header><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    
<!-- main -->
<main class="content quarto-banner-title-block" id="quarto-document-content">





<blockquote class="blockquote">
<p>In this post, we train a machine learning algorithm to distinguish the images of cats and dogs. We will go through four different models and observe which ones the best!</p>
</blockquote>
<section id="introduction-load-and-obtain-data" class="level1">
<h1>Introduction: Load and Obtain Data</h1>
<p>We start by importing the necessary packages below:</p>
<div id="cell-4" class="cell" data-execution_count="11">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> os</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> keras <span class="im">import</span> utils</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> keras</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> tensorflow_datasets <span class="im">as</span> tfds</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> tensorflow <span class="im">as</span> tf</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> tensorflow.keras <span class="im">import</span> utils</span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> tensorflow.keras <span class="im">import</span> datasets, layers, models</span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> scipy.signal <span class="im">import</span> convolve2d</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Now, we obtain our data from a sample dataset from Kaggle. As we can see, the orignal dataset contains 15695 images, however 1738 images were corrupted and therefore skipped, leaving us with 13957 images to split into training, validation, and testing sets.</p>
<div id="cell-6" class="cell" data-outputid="43608302-cc77-407f-8b52-c27a0c5053de" data-execution_count="12">
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a>train_ds, validation_ds, test_ds <span class="op">=</span> tfds.load(</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a>    <span class="st">"cats_vs_dogs"</span>,</span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a>    <span class="co"># 40% for training, 10% for validation, and 10% for test (the rest unused)</span></span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a>    split<span class="op">=</span>[<span class="st">"train[:40%]"</span>, <span class="st">"train[40%:50%]"</span>, <span class="st">"train[50%:60%]"</span>],</span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a>    as_supervised<span class="op">=</span><span class="va">True</span>,  <span class="co"># Include labels</span></span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Number of training samples: </span><span class="sc">{</span>train_ds<span class="sc">.</span>cardinality()<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Number of validation samples: </span><span class="sc">{</span>validation_ds<span class="sc">.</span>cardinality()<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb2-10"><a href="#cb2-10" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Number of test samples: </span><span class="sc">{</span>test_ds<span class="sc">.</span>cardinality()<span class="sc">}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Number of training samples: 9305
Number of validation samples: 2326
Number of test samples: 2326</code></pre>
</div>
</div>
<p>Now that we have loaded our dataset and split it into training, validation, and testing datasets, we now reshape our images into a fixed size of 150 x 150.</p>
<div id="cell-8" class="cell" data-execution_count="13">
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a>resize_fn <span class="op">=</span> keras.layers.Resizing(<span class="dv">150</span>, <span class="dv">150</span>)</span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a>train_ds <span class="op">=</span> train_ds.<span class="bu">map</span>(<span class="kw">lambda</span> x, y: (resize_fn(x), y))</span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a>validation_ds <span class="op">=</span> validation_ds.<span class="bu">map</span>(<span class="kw">lambda</span> x, y: (resize_fn(x), y))</span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a>test_ds <span class="op">=</span> test_ds.<span class="bu">map</span>(<span class="kw">lambda</span> x, y: (resize_fn(x), y))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Now, we cache our dataset and use <code>batch_size</code> to determine how many data points are gathered from our dataset at once.</p>
<div id="cell-10" class="cell" data-execution_count="14">
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> tensorflow <span class="im">import</span> data <span class="im">as</span> tf_data</span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a>batch_size <span class="op">=</span> <span class="dv">64</span></span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a>train_ds <span class="op">=</span> train_ds.batch(batch_size).prefetch(tf_data.AUTOTUNE).cache()</span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a>validation_ds <span class="op">=</span> validation_ds.batch(batch_size).prefetch(tf_data.AUTOTUNE).cache()</span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a>test_ds <span class="op">=</span> test_ds.batch(batch_size).prefetch(tf_data.AUTOTUNE).cache()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<section id="visualize-our-data" class="level2">
<h2 class="anchored" data-anchor-id="visualize-our-data">Visualize our data</h2>
<p>Now, let us create a function called <code>cats_dogs_plot</code> to visualize our dataset. We use <code>dataset.take(1)</code> to access the first batch of our data, which in this case is 64 images, and we use <code>matplotlib</code> to plot 3 images of cats in the first row and 3 images of dogs in the second row.</p>
<div id="cell-12" class="cell" data-outputid="3ad59baf-2013-42bf-e481-63c2352834ed" data-execution_count="15">
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> cats_dogs_plot(dataset):</span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a>    plt.figure(figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">10</span>))</span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> images, labels <span class="kw">in</span> dataset.take(<span class="dv">1</span>):</span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a>        i <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb6-5"><a href="#cb6-5" aria-hidden="true" tabindex="-1"></a>        cats <span class="op">=</span> <span class="dv">1</span></span>
<span id="cb6-6"><a href="#cb6-6" aria-hidden="true" tabindex="-1"></a>        dogs <span class="op">=</span> <span class="dv">4</span></span>
<span id="cb6-7"><a href="#cb6-7" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">32</span>):</span>
<span id="cb6-8"><a href="#cb6-8" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> (labels[i].numpy() <span class="op">==</span> <span class="dv">0</span>): <span class="co">#if our label == 0 or equals a cat</span></span>
<span id="cb6-9"><a href="#cb6-9" aria-hidden="true" tabindex="-1"></a>                <span class="cf">if</span> cats <span class="op">&lt;=</span> <span class="dv">3</span>: <span class="co">#once we get at least three cats, stop plotting</span></span>
<span id="cb6-10"><a href="#cb6-10" aria-hidden="true" tabindex="-1"></a>                    ax <span class="op">=</span> plt.subplot(<span class="dv">3</span>, <span class="dv">3</span>, cats)</span>
<span id="cb6-11"><a href="#cb6-11" aria-hidden="true" tabindex="-1"></a>                    plt.imshow(images[i].numpy().astype(<span class="st">"uint8"</span>))</span>
<span id="cb6-12"><a href="#cb6-12" aria-hidden="true" tabindex="-1"></a>                    plt.title(<span class="st">"cats"</span>)</span>
<span id="cb6-13"><a href="#cb6-13" aria-hidden="true" tabindex="-1"></a>                    plt.axis(<span class="st">"off"</span>)</span>
<span id="cb6-14"><a href="#cb6-14" aria-hidden="true" tabindex="-1"></a>                    cats <span class="op">+=</span> <span class="dv">1</span></span>
<span id="cb6-15"><a href="#cb6-15" aria-hidden="true" tabindex="-1"></a>                    i <span class="op">+=</span> <span class="dv">1</span></span>
<span id="cb6-16"><a href="#cb6-16" aria-hidden="true" tabindex="-1"></a>            <span class="cf">elif</span> (labels[i].numpy() <span class="op">==</span> <span class="dv">1</span>): <span class="co">#if our label == 1 or equals a dog</span></span>
<span id="cb6-17"><a href="#cb6-17" aria-hidden="true" tabindex="-1"></a>                <span class="cf">if</span> dogs <span class="op">&lt;=</span> <span class="dv">6</span>: <span class="co">#once we get at leaset three dogs, stop plotting</span></span>
<span id="cb6-18"><a href="#cb6-18" aria-hidden="true" tabindex="-1"></a>                    ax <span class="op">=</span> plt.subplot(<span class="dv">3</span>, <span class="dv">3</span>, dogs)</span>
<span id="cb6-19"><a href="#cb6-19" aria-hidden="true" tabindex="-1"></a>                    plt.imshow(images[i].numpy().astype(<span class="st">"uint8"</span>))</span>
<span id="cb6-20"><a href="#cb6-20" aria-hidden="true" tabindex="-1"></a>                    plt.title(<span class="st">"dogs"</span>)</span>
<span id="cb6-21"><a href="#cb6-21" aria-hidden="true" tabindex="-1"></a>                    plt.axis(<span class="st">"off"</span>)</span>
<span id="cb6-22"><a href="#cb6-22" aria-hidden="true" tabindex="-1"></a>                    dogs <span class="op">+=</span> <span class="dv">1</span></span>
<span id="cb6-23"><a href="#cb6-23" aria-hidden="true" tabindex="-1"></a>                    i <span class="op">+=</span> <span class="dv">1</span></span>
<span id="cb6-24"><a href="#cb6-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-25"><a href="#cb6-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-26"><a href="#cb6-26" aria-hidden="true" tabindex="-1"></a>cats_dogs_plot(train_ds)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="ClassificationDogCat (1)_files/figure-html/cell-6-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p>As you can see, our function works as intended!</p>
</section>
<section id="analyzing-our-dataset" class="level2">
<h2 class="anchored" data-anchor-id="analyzing-our-dataset">Analyzing our dataset</h2>
<p>Now, let us see how many dogs and cats images there are total in our training set. To do so, we create an iterator called <code>labels_iterator</code> and if the label equals 0, we add a tally to our <code>cats</code> variable and if the label equals 1, we add a tally to our <code>dogs</code> variable.</p>
<div id="cell-15" class="cell" data-execution_count="16">
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a>labels_iterator<span class="op">=</span> train_ds.unbatch().<span class="bu">map</span>(<span class="kw">lambda</span> image, label: label).as_numpy_iterator()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="cell-16" class="cell" data-outputid="68933dfb-a72e-4e76-ae42-7d185405be34" data-execution_count="17">
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a>cats <span class="op">=</span> dogs <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> element <span class="kw">in</span> labels_iterator: <span class="co">#for each label in our labels_iterator</span></span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> element <span class="op">==</span> <span class="dv">0</span>:</span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a>        cats <span class="op">+=</span> <span class="dv">1</span></span>
<span id="cb8-5"><a href="#cb8-5" aria-hidden="true" tabindex="-1"></a>    <span class="cf">else</span>:</span>
<span id="cb8-6"><a href="#cb8-6" aria-hidden="true" tabindex="-1"></a>        dogs <span class="op">+=</span> <span class="dv">1</span></span>
<span id="cb8-7"><a href="#cb8-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-8"><a href="#cb8-8" aria-hidden="true" tabindex="-1"></a>cats, dogs</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="17">
<pre><code>(4637, 4668)</code></pre>
</div>
</div>
<div id="cell-17" class="cell" data-outputid="d81645a0-b776-494b-d5f7-08df209dfca9" data-execution_count="18">
<div class="sourceCode cell-code" id="cb10"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a>dogs<span class="op">/</span>(cats<span class="op">+</span>dogs)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="18">
<pre><code>0.5016657710908113</code></pre>
</div>
</div>
<p>It appears that our dataset is nearly balanced. There are 4637 cats and 4668 dogs, meaning that if we were to guess all dogs, we would have a 50.16 percent accuracy rate.</p>
</section>
</section>
<section id="first-model" class="level1">
<h1>1. First Model</h1>
<p>We now create a simple <code>keras.Sequential</code> model. In this model, we included three <code>Conv2D</code> laters, two <code>MaxPooling2D</code> layers, one <code>Flatten</code> layer, two <code>Dense</code> layers, and one <code>Dropout</code> layer.</p>
<div id="cell-21" class="cell" data-execution_count="40">
<div class="sourceCode cell-code" id="cb12"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a>model1 <span class="op">=</span> models.Sequential([</span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a>    layers.Conv2D(<span class="dv">32</span>, (<span class="dv">3</span>, <span class="dv">3</span>), activation<span class="op">=</span><span class="st">'relu'</span>, input_shape<span class="op">=</span>(<span class="dv">150</span>, <span class="dv">150</span>, <span class="dv">3</span>)),</span>
<span id="cb12-3"><a href="#cb12-3" aria-hidden="true" tabindex="-1"></a>    layers.MaxPooling2D((<span class="dv">2</span>, <span class="dv">2</span>)),</span>
<span id="cb12-4"><a href="#cb12-4" aria-hidden="true" tabindex="-1"></a>    layers.Conv2D(<span class="dv">32</span>, (<span class="dv">3</span>, <span class="dv">3</span>), activation<span class="op">=</span><span class="st">'relu'</span>),</span>
<span id="cb12-5"><a href="#cb12-5" aria-hidden="true" tabindex="-1"></a>    layers.MaxPooling2D((<span class="dv">2</span>, <span class="dv">2</span>)),</span>
<span id="cb12-6"><a href="#cb12-6" aria-hidden="true" tabindex="-1"></a>    layers.Conv2D(<span class="dv">64</span>, (<span class="dv">3</span>, <span class="dv">3</span>), activation<span class="op">=</span><span class="st">'relu'</span>),</span>
<span id="cb12-7"><a href="#cb12-7" aria-hidden="true" tabindex="-1"></a>    layers.Flatten(),</span>
<span id="cb12-8"><a href="#cb12-8" aria-hidden="true" tabindex="-1"></a>    layers.Dense(<span class="dv">64</span>, activation<span class="op">=</span><span class="st">'relu'</span>),</span>
<span id="cb12-9"><a href="#cb12-9" aria-hidden="true" tabindex="-1"></a>    layers.Dropout(<span class="fl">.15</span>),</span>
<span id="cb12-10"><a href="#cb12-10" aria-hidden="true" tabindex="-1"></a>    layers.Dense(<span class="dv">2</span>)</span>
<span id="cb12-11"><a href="#cb12-11" aria-hidden="true" tabindex="-1"></a>])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Now let us run a summary of our model.</p>
<div id="cell-23" class="cell" data-outputid="5845e6e2-0d2a-41e1-d68e-09ffb03bbc04" data-execution_count="41">
<div class="sourceCode cell-code" id="cb13"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a>model1.summary()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Model: "sequential_7"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 conv2d_9 (Conv2D)           (None, 148, 148, 32)      896       
                                                                 
 max_pooling2d_6 (MaxPoolin  (None, 74, 74, 32)        0         
 g2D)                                                            
                                                                 
 conv2d_10 (Conv2D)          (None, 72, 72, 32)        9248      
                                                                 
 max_pooling2d_7 (MaxPoolin  (None, 36, 36, 32)        0         
 g2D)                                                            
                                                                 
 conv2d_11 (Conv2D)          (None, 34, 34, 64)        18496     
                                                                 
 flatten_3 (Flatten)         (None, 73984)             0         
                                                                 
 dense_8 (Dense)             (None, 64)                4735040   
                                                                 
 dropout_4 (Dropout)         (None, 64)                0         
                                                                 
 dense_9 (Dense)             (None, 2)                 130       
                                                                 
=================================================================
Total params: 4763810 (18.17 MB)
Trainable params: 4763810 (18.17 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________</code></pre>
</div>
</div>
<p>Wow! 4,763,810 parameters covering 18.17 MB, that’s a lot of data! For <code>Conv2D</code>, the first argument we use represents how many dimensions we want for our output, the second argument represents kernel size, the third argument represents our activation method, and the last argument for the first <code>Conv2D</code> layer is our input shape. In between each <code>conv2d</code> layer, we use <code>max_pooling</code> in order to reduce the size of our data. Then, we <code>flatten</code> our data in order to reduce our data from 2D down to 1D for the <code>dense</code> layer which reduces the output shape and adds extra parameters. Finally, the <code>dropout</code> layer helps with overfitting while the final <code>dense</code> layer uses the number 2 as we have two classes in our dataset which we hope to predict.</p>
<p>Now, we compile our model with our optimizer as <code>adam</code>, loss function as <code>SparseCategoricalCrossEntropy</code>, and metrics as <code>accuracy</code> over 20 <code>epochs</code>.</p>
<div id="cell-25" class="cell" data-outputid="2fce0a5c-a4ac-476c-fe7e-9baa53c8c7b0" data-execution_count="42">
<div class="sourceCode cell-code" id="cb15"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a>model1.<span class="bu">compile</span>(optimizer<span class="op">=</span><span class="st">'adam'</span>,</span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a>              loss <span class="op">=</span> tf.keras.losses.SparseCategoricalCrossentropy(from_logits<span class="op">=</span><span class="va">True</span>),</span>
<span id="cb15-3"><a href="#cb15-3" aria-hidden="true" tabindex="-1"></a>              metrics <span class="op">=</span> [<span class="st">'accuracy'</span>])</span>
<span id="cb15-4"><a href="#cb15-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-5"><a href="#cb15-5" aria-hidden="true" tabindex="-1"></a>history <span class="op">=</span> model1.fit(train_ds,</span>
<span id="cb15-6"><a href="#cb15-6" aria-hidden="true" tabindex="-1"></a>                     epochs<span class="op">=</span><span class="dv">20</span>,</span>
<span id="cb15-7"><a href="#cb15-7" aria-hidden="true" tabindex="-1"></a>                     validation_data<span class="op">=</span>validation_ds)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Epoch 1/20
146/146 [==============================] - 8s 31ms/step - loss: 14.1833 - accuracy: 0.5396 - val_loss: 0.6776 - val_accuracy: 0.5593
Epoch 2/20
146/146 [==============================] - 4s 30ms/step - loss: 0.6606 - accuracy: 0.5873 - val_loss: 0.6701 - val_accuracy: 0.5666
Epoch 3/20
146/146 [==============================] - 4s 30ms/step - loss: 0.6290 - accuracy: 0.6460 - val_loss: 0.6839 - val_accuracy: 0.6019
Epoch 4/20
146/146 [==============================] - 4s 30ms/step - loss: 0.5549 - accuracy: 0.7053 - val_loss: 0.7130 - val_accuracy: 0.5744
Epoch 5/20
146/146 [==============================] - 4s 31ms/step - loss: 0.4703 - accuracy: 0.7636 - val_loss: 0.7167 - val_accuracy: 0.5765
Epoch 6/20
146/146 [==============================] - 4s 30ms/step - loss: 0.4088 - accuracy: 0.8040 - val_loss: 0.8278 - val_accuracy: 0.5559
Epoch 7/20
146/146 [==============================] - 4s 30ms/step - loss: 0.3951 - accuracy: 0.8101 - val_loss: 0.8848 - val_accuracy: 0.5765
Epoch 8/20
146/146 [==============================] - 4s 30ms/step - loss: 0.3468 - accuracy: 0.8369 - val_loss: 0.8763 - val_accuracy: 0.5765
Epoch 9/20
146/146 [==============================] - 5s 35ms/step - loss: 0.3006 - accuracy: 0.8602 - val_loss: 1.0907 - val_accuracy: 0.5907
Epoch 10/20
146/146 [==============================] - 5s 38ms/step - loss: 0.2897 - accuracy: 0.8696 - val_loss: 1.0418 - val_accuracy: 0.5782
Epoch 11/20
146/146 [==============================] - 5s 33ms/step - loss: 0.2574 - accuracy: 0.8859 - val_loss: 1.3849 - val_accuracy: 0.5821
Epoch 12/20
146/146 [==============================] - 5s 32ms/step - loss: 0.2531 - accuracy: 0.8940 - val_loss: 1.3706 - val_accuracy: 0.5800
Epoch 13/20
146/146 [==============================] - 4s 30ms/step - loss: 0.2191 - accuracy: 0.9070 - val_loss: 1.6147 - val_accuracy: 0.5722
Epoch 14/20
146/146 [==============================] - 5s 33ms/step - loss: 0.2047 - accuracy: 0.9171 - val_loss: 1.3552 - val_accuracy: 0.6019
Epoch 15/20
146/146 [==============================] - 5s 33ms/step - loss: 0.2003 - accuracy: 0.9225 - val_loss: 1.4611 - val_accuracy: 0.6040
Epoch 16/20
146/146 [==============================] - 5s 32ms/step - loss: 0.1952 - accuracy: 0.9235 - val_loss: 1.9034 - val_accuracy: 0.5959
Epoch 17/20
146/146 [==============================] - 5s 35ms/step - loss: 0.1778 - accuracy: 0.9315 - val_loss: 1.9759 - val_accuracy: 0.6092
Epoch 18/20
146/146 [==============================] - 5s 33ms/step - loss: 0.1619 - accuracy: 0.9361 - val_loss: 2.0059 - val_accuracy: 0.6122
Epoch 19/20
146/146 [==============================] - 4s 30ms/step - loss: 0.1443 - accuracy: 0.9528 - val_loss: 2.1377 - val_accuracy: 0.6187
Epoch 20/20
146/146 [==============================] - 4s 30ms/step - loss: 0.1090 - accuracy: 0.9622 - val_loss: 2.1909 - val_accuracy: 0.6105</code></pre>
</div>
</div>
<p>We now plot our training and validation accuracies across the 20 <code>epochs</code>.</p>
<div id="cell-27" class="cell" data-outputid="dd473053-23ba-4185-98d6-8bf489922263" data-execution_count="44">
<div class="sourceCode cell-code" id="cb17"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a>plt.plot(history.history[<span class="st">"accuracy"</span>], label <span class="op">=</span> <span class="st">"training"</span>)</span>
<span id="cb17-2"><a href="#cb17-2" aria-hidden="true" tabindex="-1"></a>plt.plot(history.history[<span class="st">"val_accuracy"</span>], label <span class="op">=</span> <span class="st">"validation"</span>)</span>
<span id="cb17-3"><a href="#cb17-3" aria-hidden="true" tabindex="-1"></a>plt.gca().<span class="bu">set</span>(xlabel <span class="op">=</span> <span class="st">"epoch"</span>, ylabel <span class="op">=</span> <span class="st">"accuracy"</span>)</span>
<span id="cb17-4"><a href="#cb17-4" aria-hidden="true" tabindex="-1"></a>plt.legend()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="ClassificationDogCat (1)_files/figure-html/cell-13-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<section id="comments" class="level2">
<h2 class="anchored" data-anchor-id="comments">Comments</h2>
<ul>
<li>The accuracy of our model stabilized around <strong>56 to 60 percent</strong></li>
<li>Compared with our baseline of 50.16 percent, our model did a bit better, but we can still do much better</li>
<li>There is a significant overfitting issue as our training accuracy is around 98 percent while our validation accuracy is nearly thirty percent lower.</li>
</ul>
</section>
</section>
<section id="model-two-data-augmentation" class="level1">
<h1>2. Model Two: Data Augmentation</h1>
<p>Now we shall use data augmentation using <code>RandomFlip</code> and <code>Random Rotation</code> from <code>keras.layers</code>. These methods flip and rotate our images randomly and our goal is to have our model learn to recognize these altered images are just transformed images of the original image.</p>
<p>First, let us create our two layers <code>random_flip</code> and <code>random_rotation</code>. Then, we create a variable called <code>data_augmentation</code> which is a combination of the two such that we can use it for our model later.</p>
<div id="cell-31" class="cell" data-execution_count="46">
<div class="sourceCode cell-code" id="cb18"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a>random_flip <span class="op">=</span> tf.keras.Sequential([</span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"></a>  tf.keras.layers.RandomFlip(<span class="st">'vertical'</span>, input_shape<span class="op">=</span>(<span class="dv">150</span>,<span class="dv">150</span>,<span class="dv">3</span>))</span>
<span id="cb18-3"><a href="#cb18-3" aria-hidden="true" tabindex="-1"></a>])</span>
<span id="cb18-4"><a href="#cb18-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-5"><a href="#cb18-5" aria-hidden="true" tabindex="-1"></a>random_rotation <span class="op">=</span> tf.keras.Sequential([</span>
<span id="cb18-6"><a href="#cb18-6" aria-hidden="true" tabindex="-1"></a>  tf.keras.layers.RandomRotation(<span class="fl">0.2</span>, input_shape<span class="op">=</span>(<span class="dv">150</span>,<span class="dv">150</span>,<span class="dv">3</span>))</span>
<span id="cb18-7"><a href="#cb18-7" aria-hidden="true" tabindex="-1"></a>])</span>
<span id="cb18-8"><a href="#cb18-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-9"><a href="#cb18-9" aria-hidden="true" tabindex="-1"></a>data_augmentation <span class="op">=</span> tf.keras.Sequential([</span>
<span id="cb18-10"><a href="#cb18-10" aria-hidden="true" tabindex="-1"></a>  tf.keras.layers.RandomFlip(<span class="st">'vertical'</span>, input_shape<span class="op">=</span>(<span class="dv">150</span>,<span class="dv">150</span>,<span class="dv">3</span>)),</span>
<span id="cb18-11"><a href="#cb18-11" aria-hidden="true" tabindex="-1"></a>  tf.keras.layers.RandomRotation(<span class="fl">0.2</span>),</span>
<span id="cb18-12"><a href="#cb18-12" aria-hidden="true" tabindex="-1"></a>])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Now, let us apply <code>random_flip</code> and <code>random_rotation</code> to images such that we can visualize what these layers are doing. We expect to see 6 images of a randomly flipped image and then 6 images of a randomly rotated image.</p>
<div id="cell-33" class="cell" data-outputid="458966ef-37a4-47f7-f595-c087e9ff09dc" data-execution_count="47">
<div class="sourceCode cell-code" id="cb19"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> image, _ <span class="kw">in</span> train_ds.take(<span class="dv">1</span>):</span>
<span id="cb19-2"><a href="#cb19-2" aria-hidden="true" tabindex="-1"></a>  plt.figure(figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">10</span>))</span>
<span id="cb19-3"><a href="#cb19-3" aria-hidden="true" tabindex="-1"></a>  first_image <span class="op">=</span> image[<span class="dv">0</span>] <span class="co">#take the first image in our batch</span></span>
<span id="cb19-4"><a href="#cb19-4" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">6</span>): <span class="co">#plots six images</span></span>
<span id="cb19-5"><a href="#cb19-5" aria-hidden="true" tabindex="-1"></a>    ax <span class="op">=</span> plt.subplot(<span class="dv">3</span>, <span class="dv">3</span>, i <span class="op">+</span> <span class="dv">1</span>)</span>
<span id="cb19-6"><a href="#cb19-6" aria-hidden="true" tabindex="-1"></a>    augmented_image <span class="op">=</span> random_flip(tf.expand_dims(first_image, <span class="dv">0</span>)) <span class="co">#randomly flips our image</span></span>
<span id="cb19-7"><a href="#cb19-7" aria-hidden="true" tabindex="-1"></a>    plt.imshow(augmented_image[<span class="dv">0</span>] <span class="op">/</span> <span class="dv">255</span>)</span>
<span id="cb19-8"><a href="#cb19-8" aria-hidden="true" tabindex="-1"></a>    plt.axis(<span class="st">'off'</span>)</span>
<span id="cb19-9"><a href="#cb19-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-10"><a href="#cb19-10" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> image, _ <span class="kw">in</span> train_ds.take(<span class="dv">1</span>):</span>
<span id="cb19-11"><a href="#cb19-11" aria-hidden="true" tabindex="-1"></a>  plt.figure(figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">10</span>))</span>
<span id="cb19-12"><a href="#cb19-12" aria-hidden="true" tabindex="-1"></a>  first_image <span class="op">=</span> image[<span class="dv">1</span>] <span class="co">#takes the second image in our batch</span></span>
<span id="cb19-13"><a href="#cb19-13" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">6</span>): <span class="co">#plots 6 images</span></span>
<span id="cb19-14"><a href="#cb19-14" aria-hidden="true" tabindex="-1"></a>    ax <span class="op">=</span> plt.subplot(<span class="dv">3</span>, <span class="dv">3</span>, i <span class="op">+</span> <span class="dv">1</span>)</span>
<span id="cb19-15"><a href="#cb19-15" aria-hidden="true" tabindex="-1"></a>    augmented_image <span class="op">=</span> random_rotation(tf.expand_dims(first_image, <span class="dv">0</span>)) <span class="co">#randomly rotates our image</span></span>
<span id="cb19-16"><a href="#cb19-16" aria-hidden="true" tabindex="-1"></a>    plt.imshow(augmented_image[<span class="dv">0</span>] <span class="op">/</span> <span class="dv">255</span>)</span>
<span id="cb19-17"><a href="#cb19-17" aria-hidden="true" tabindex="-1"></a>    plt.axis(<span class="st">'off'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="ClassificationDogCat (1)_files/figure-html/cell-15-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="ClassificationDogCat (1)_files/figure-html/cell-15-output-2.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p>It looks like our layers are doing what we want it to do from the visualization! Now let us implement it into our model.</p>
<div id="cell-35" class="cell" data-execution_count="48">
<div class="sourceCode cell-code" id="cb20"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a>model2 <span class="op">=</span> models.Sequential([</span>
<span id="cb20-2"><a href="#cb20-2" aria-hidden="true" tabindex="-1"></a>    data_augmentation,</span>
<span id="cb20-3"><a href="#cb20-3" aria-hidden="true" tabindex="-1"></a>    layers.Conv2D(<span class="dv">32</span>, (<span class="dv">3</span>, <span class="dv">3</span>), activation<span class="op">=</span><span class="st">'relu'</span>),</span>
<span id="cb20-4"><a href="#cb20-4" aria-hidden="true" tabindex="-1"></a>    layers.MaxPooling2D((<span class="dv">2</span>, <span class="dv">2</span>)),</span>
<span id="cb20-5"><a href="#cb20-5" aria-hidden="true" tabindex="-1"></a>    layers.Conv2D(<span class="dv">32</span>, (<span class="dv">3</span>, <span class="dv">3</span>), activation<span class="op">=</span><span class="st">'relu'</span>),</span>
<span id="cb20-6"><a href="#cb20-6" aria-hidden="true" tabindex="-1"></a>    layers.MaxPooling2D((<span class="dv">2</span>, <span class="dv">2</span>)),</span>
<span id="cb20-7"><a href="#cb20-7" aria-hidden="true" tabindex="-1"></a>    layers.Conv2D(<span class="dv">64</span>, (<span class="dv">3</span>, <span class="dv">3</span>), activation<span class="op">=</span><span class="st">'relu'</span>),</span>
<span id="cb20-8"><a href="#cb20-8" aria-hidden="true" tabindex="-1"></a>    layers.Flatten(),</span>
<span id="cb20-9"><a href="#cb20-9" aria-hidden="true" tabindex="-1"></a>    layers.Dropout(<span class="fl">.15</span>),</span>
<span id="cb20-10"><a href="#cb20-10" aria-hidden="true" tabindex="-1"></a>    layers.Dense(<span class="dv">64</span>, activation<span class="op">=</span><span class="st">'relu'</span>),</span>
<span id="cb20-11"><a href="#cb20-11" aria-hidden="true" tabindex="-1"></a>    layers.Dense(<span class="dv">2</span>)</span>
<span id="cb20-12"><a href="#cb20-12" aria-hidden="true" tabindex="-1"></a>])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Let’s look at our model summary.</p>
<div id="cell-37" class="cell" data-outputid="ea406812-67bc-4fe1-fb2c-d67ef1cdaee5" data-execution_count="49">
<div class="sourceCode cell-code" id="cb21"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a>model2.summary()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Model: "sequential_14"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 sequential_13 (Sequential)  (None, 150, 150, 3)       0         
                                                                 
 conv2d_12 (Conv2D)          (None, 148, 148, 32)      896       
                                                                 
 max_pooling2d_8 (MaxPoolin  (None, 74, 74, 32)        0         
 g2D)                                                            
                                                                 
 conv2d_13 (Conv2D)          (None, 72, 72, 32)        9248      
                                                                 
 max_pooling2d_9 (MaxPoolin  (None, 36, 36, 32)        0         
 g2D)                                                            
                                                                 
 conv2d_14 (Conv2D)          (None, 34, 34, 64)        18496     
                                                                 
 flatten_4 (Flatten)         (None, 73984)             0         
                                                                 
 dropout_5 (Dropout)         (None, 73984)             0         
                                                                 
 dense_10 (Dense)            (None, 64)                4735040   
                                                                 
 dense_11 (Dense)            (None, 2)                 130       
                                                                 
=================================================================
Total params: 4763810 (18.17 MB)
Trainable params: 4763810 (18.17 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________</code></pre>
</div>
</div>
<p>Now let’s train the model as we did before.</p>
<div id="cell-39" class="cell" data-outputid="77a2eab5-82c8-4f5c-f11c-711e3b719073" data-execution_count="50">
<div class="sourceCode cell-code" id="cb23"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a>model2.<span class="bu">compile</span>(optimizer<span class="op">=</span><span class="st">'adam'</span>,</span>
<span id="cb23-2"><a href="#cb23-2" aria-hidden="true" tabindex="-1"></a>              loss <span class="op">=</span> tf.keras.losses.SparseCategoricalCrossentropy(from_logits<span class="op">=</span><span class="va">True</span>),</span>
<span id="cb23-3"><a href="#cb23-3" aria-hidden="true" tabindex="-1"></a>              metrics <span class="op">=</span> [<span class="st">'accuracy'</span>])</span>
<span id="cb23-4"><a href="#cb23-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-5"><a href="#cb23-5" aria-hidden="true" tabindex="-1"></a>history <span class="op">=</span> model2.fit(train_ds,</span>
<span id="cb23-6"><a href="#cb23-6" aria-hidden="true" tabindex="-1"></a>                     epochs<span class="op">=</span><span class="dv">20</span>,</span>
<span id="cb23-7"><a href="#cb23-7" aria-hidden="true" tabindex="-1"></a>                     validation_data<span class="op">=</span>validation_ds)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Epoch 1/20
146/146 [==============================] - 7s 33ms/step - loss: 9.6744 - accuracy: 0.5373 - val_loss: 0.6755 - val_accuracy: 0.5516
Epoch 2/20
146/146 [==============================] - 5s 32ms/step - loss: 0.6557 - accuracy: 0.6097 - val_loss: 0.6439 - val_accuracy: 0.6376
Epoch 3/20
146/146 [==============================] - 5s 33ms/step - loss: 0.6399 - accuracy: 0.6364 - val_loss: 0.6281 - val_accuracy: 0.6513
Epoch 4/20
146/146 [==============================] - 5s 32ms/step - loss: 0.6309 - accuracy: 0.6440 - val_loss: 0.6234 - val_accuracy: 0.6543
Epoch 5/20
146/146 [==============================] - 5s 33ms/step - loss: 0.6164 - accuracy: 0.6604 - val_loss: 0.5986 - val_accuracy: 0.6965
Epoch 6/20
146/146 [==============================] - 5s 35ms/step - loss: 0.6057 - accuracy: 0.6725 - val_loss: 0.5887 - val_accuracy: 0.7029
Epoch 7/20
146/146 [==============================] - 5s 36ms/step - loss: 0.5879 - accuracy: 0.6952 - val_loss: 0.5651 - val_accuracy: 0.7154
Epoch 8/20
146/146 [==============================] - 5s 36ms/step - loss: 0.5889 - accuracy: 0.6818 - val_loss: 0.5818 - val_accuracy: 0.7029
Epoch 9/20
146/146 [==============================] - 5s 36ms/step - loss: 0.5814 - accuracy: 0.6940 - val_loss: 0.5614 - val_accuracy: 0.7227
Epoch 10/20
146/146 [==============================] - 5s 34ms/step - loss: 0.5605 - accuracy: 0.7053 - val_loss: 0.5478 - val_accuracy: 0.7352
Epoch 11/20
146/146 [==============================] - 5s 33ms/step - loss: 0.5549 - accuracy: 0.7184 - val_loss: 0.5409 - val_accuracy: 0.7369
Epoch 12/20
146/146 [==============================] - 5s 36ms/step - loss: 0.5518 - accuracy: 0.7188 - val_loss: 0.5888 - val_accuracy: 0.7128
Epoch 13/20
146/146 [==============================] - 5s 33ms/step - loss: 0.5471 - accuracy: 0.7244 - val_loss: 0.5338 - val_accuracy: 0.7339
Epoch 14/20
146/146 [==============================] - 5s 33ms/step - loss: 0.5348 - accuracy: 0.7305 - val_loss: 0.5772 - val_accuracy: 0.7425
Epoch 15/20
146/146 [==============================] - 5s 32ms/step - loss: 0.5297 - accuracy: 0.7354 - val_loss: 0.5533 - val_accuracy: 0.7257
Epoch 16/20
146/146 [==============================] - 5s 32ms/step - loss: 0.5200 - accuracy: 0.7394 - val_loss: 0.5329 - val_accuracy: 0.7498
Epoch 17/20
146/146 [==============================] - 5s 32ms/step - loss: 0.5245 - accuracy: 0.7438 - val_loss: 0.5421 - val_accuracy: 0.7352
Epoch 18/20
146/146 [==============================] - 5s 32ms/step - loss: 0.5174 - accuracy: 0.7480 - val_loss: 0.5395 - val_accuracy: 0.7425
Epoch 19/20
146/146 [==============================] - 5s 33ms/step - loss: 0.5017 - accuracy: 0.7575 - val_loss: 0.5095 - val_accuracy: 0.7674
Epoch 20/20
146/146 [==============================] - 5s 32ms/step - loss: 0.5008 - accuracy: 0.7585 - val_loss: 0.5451 - val_accuracy: 0.7588</code></pre>
</div>
</div>
<p>Finally, plot the training and validation accuracies.</p>
<div id="cell-41" class="cell" data-outputid="909ad604-5c63-470c-de33-9dc6f364f55f" data-execution_count="28">
<div class="sourceCode cell-code" id="cb25"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb25-1"><a href="#cb25-1" aria-hidden="true" tabindex="-1"></a>plt.plot(history.history[<span class="st">"accuracy"</span>], label <span class="op">=</span> <span class="st">"training"</span>)</span>
<span id="cb25-2"><a href="#cb25-2" aria-hidden="true" tabindex="-1"></a>plt.plot(history.history[<span class="st">"val_accuracy"</span>], label <span class="op">=</span> <span class="st">"validation"</span>)</span>
<span id="cb25-3"><a href="#cb25-3" aria-hidden="true" tabindex="-1"></a>plt.gca().<span class="bu">set</span>(xlabel <span class="op">=</span> <span class="st">"epoch"</span>, ylabel <span class="op">=</span> <span class="st">"accuracy"</span>)</span>
<span id="cb25-4"><a href="#cb25-4" aria-hidden="true" tabindex="-1"></a>plt.legend()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="ClassificationDogCat (1)_files/figure-html/cell-19-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<section id="comments-1" class="level2">
<h2 class="anchored" data-anchor-id="comments-1">Comments</h2>
<ul>
<li>The accuracy of our model now appears to be around <strong>75 percent</strong></li>
<li>This is significantly better than the first model’s accuracy of 55 percent and our baseline of 50.16 percent.</li>
<li>There does not appear to be overfitting as our validation accuracy is better than our training accuracy</li>
</ul>
</section>
</section>
<section id="model-three-data-preprocessing" class="level1">
<h1>4. Model Three: Data Preprocessing</h1>
<p>We now look to add a preprocessing step to our model. The following code scales down our RGB values to numbers that are easier to compute. In this case, the original data has pixels with RGB values between 0 and 255, but many models will train faster with RGB values normalized between 0 and 1, or possibly between -1 and 1. These are mathematically identical situations, since we can always just scale the weights. Since we handle scaling prior to the training process, we can spend more of our training energy handling actual signal in the data and less energy having the weights adjust to the data scale.</p>
<div id="cell-45" class="cell" data-execution_count="29">
<div class="sourceCode cell-code" id="cb26"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb26-1"><a href="#cb26-1" aria-hidden="true" tabindex="-1"></a>i <span class="op">=</span> keras.Input(shape<span class="op">=</span>(<span class="dv">150</span>, <span class="dv">150</span>, <span class="dv">3</span>))</span>
<span id="cb26-2"><a href="#cb26-2" aria-hidden="true" tabindex="-1"></a><span class="co"># The pixel values have the range of (0, 255), but many models will work better if rescaled to (-1, 1.)</span></span>
<span id="cb26-3"><a href="#cb26-3" aria-hidden="true" tabindex="-1"></a><span class="co"># outputs: `(inputs * scale) + offset`</span></span>
<span id="cb26-4"><a href="#cb26-4" aria-hidden="true" tabindex="-1"></a>scale_layer <span class="op">=</span> keras.layers.Rescaling(scale<span class="op">=</span><span class="dv">1</span> <span class="op">/</span> <span class="fl">127.5</span>, offset<span class="op">=-</span><span class="dv">1</span>)</span>
<span id="cb26-5"><a href="#cb26-5" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> scale_layer(i)</span>
<span id="cb26-6"><a href="#cb26-6" aria-hidden="true" tabindex="-1"></a>preprocessor <span class="op">=</span> keras.Model(inputs <span class="op">=</span> [i], outputs <span class="op">=</span> [x])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Here is <code>model3</code> which incorporates our <code>preprocessor</code> layer.</p>
<div id="cell-47" class="cell" data-execution_count="30">
<div class="sourceCode cell-code" id="cb27"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb27-1"><a href="#cb27-1" aria-hidden="true" tabindex="-1"></a>model3 <span class="op">=</span> models.Sequential([</span>
<span id="cb27-2"><a href="#cb27-2" aria-hidden="true" tabindex="-1"></a>    preprocessor,</span>
<span id="cb27-3"><a href="#cb27-3" aria-hidden="true" tabindex="-1"></a>    data_augmentation,</span>
<span id="cb27-4"><a href="#cb27-4" aria-hidden="true" tabindex="-1"></a>    layers.Conv2D(<span class="dv">32</span>, (<span class="dv">3</span>, <span class="dv">3</span>), activation<span class="op">=</span><span class="st">'relu'</span>),</span>
<span id="cb27-5"><a href="#cb27-5" aria-hidden="true" tabindex="-1"></a>    layers.MaxPooling2D((<span class="dv">2</span>, <span class="dv">2</span>)),</span>
<span id="cb27-6"><a href="#cb27-6" aria-hidden="true" tabindex="-1"></a>    layers.Conv2D(<span class="dv">32</span>, (<span class="dv">3</span>, <span class="dv">3</span>), activation<span class="op">=</span><span class="st">'relu'</span>),</span>
<span id="cb27-7"><a href="#cb27-7" aria-hidden="true" tabindex="-1"></a>    layers.MaxPooling2D((<span class="dv">2</span>, <span class="dv">2</span>)),</span>
<span id="cb27-8"><a href="#cb27-8" aria-hidden="true" tabindex="-1"></a>    layers.Conv2D(<span class="dv">64</span>, (<span class="dv">3</span>, <span class="dv">3</span>), activation<span class="op">=</span><span class="st">'relu'</span>),</span>
<span id="cb27-9"><a href="#cb27-9" aria-hidden="true" tabindex="-1"></a>    layers.Flatten(),</span>
<span id="cb27-10"><a href="#cb27-10" aria-hidden="true" tabindex="-1"></a>    layers.Dropout(<span class="fl">.15</span>),</span>
<span id="cb27-11"><a href="#cb27-11" aria-hidden="true" tabindex="-1"></a>    layers.Dense(<span class="dv">64</span>, activation<span class="op">=</span><span class="st">'relu'</span>),</span>
<span id="cb27-12"><a href="#cb27-12" aria-hidden="true" tabindex="-1"></a>    layers.Dense(<span class="dv">2</span>)</span>
<span id="cb27-13"><a href="#cb27-13" aria-hidden="true" tabindex="-1"></a>])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>We call <code>model3</code> summary.</p>
<div id="cell-49" class="cell" data-outputid="3f9ba22d-e8a4-43f5-fabd-70ce9e0a4184" data-execution_count="31">
<div class="sourceCode cell-code" id="cb28"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb28-1"><a href="#cb28-1" aria-hidden="true" tabindex="-1"></a>model3.summary()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Model: "sequential_5"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 model (Functional)          (None, 150, 150, 3)       0         
                                                                 
 sequential_3 (Sequential)   (None, 150, 150, 3)       0         
                                                                 
 conv2d_6 (Conv2D)           (None, 148, 148, 32)      896       
                                                                 
 max_pooling2d_4 (MaxPoolin  (None, 74, 74, 32)        0         
 g2D)                                                            
                                                                 
 conv2d_7 (Conv2D)           (None, 72, 72, 32)        9248      
                                                                 
 max_pooling2d_5 (MaxPoolin  (None, 36, 36, 32)        0         
 g2D)                                                            
                                                                 
 conv2d_8 (Conv2D)           (None, 34, 34, 64)        18496     
                                                                 
 flatten_2 (Flatten)         (None, 73984)             0         
                                                                 
 dropout_2 (Dropout)         (None, 73984)             0         
                                                                 
 dense_4 (Dense)             (None, 64)                4735040   
                                                                 
 dense_5 (Dense)             (None, 2)                 130       
                                                                 
=================================================================
Total params: 4763810 (18.17 MB)
Trainable params: 4763810 (18.17 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________</code></pre>
</div>
</div>
<p>And we train just as we did before on prior models.</p>
<div id="cell-51" class="cell" data-outputid="13bfbebb-0614-420c-8348-3f4b22303990" data-execution_count="32">
<div class="sourceCode cell-code" id="cb30"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb30-1"><a href="#cb30-1" aria-hidden="true" tabindex="-1"></a>model3.<span class="bu">compile</span>(optimizer<span class="op">=</span><span class="st">'adam'</span>,</span>
<span id="cb30-2"><a href="#cb30-2" aria-hidden="true" tabindex="-1"></a>              loss <span class="op">=</span> tf.keras.losses.SparseCategoricalCrossentropy(from_logits<span class="op">=</span><span class="va">True</span>),</span>
<span id="cb30-3"><a href="#cb30-3" aria-hidden="true" tabindex="-1"></a>              metrics <span class="op">=</span> [<span class="st">'accuracy'</span>])</span>
<span id="cb30-4"><a href="#cb30-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-5"><a href="#cb30-5" aria-hidden="true" tabindex="-1"></a>history <span class="op">=</span> model3.fit(train_ds,</span>
<span id="cb30-6"><a href="#cb30-6" aria-hidden="true" tabindex="-1"></a>                     epochs<span class="op">=</span><span class="dv">20</span>,</span>
<span id="cb30-7"><a href="#cb30-7" aria-hidden="true" tabindex="-1"></a>                     validation_data<span class="op">=</span>validation_ds)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Epoch 1/20
146/146 [==============================] - 7s 35ms/step - loss: 0.6745 - accuracy: 0.6176 - val_loss: 0.5748 - val_accuracy: 0.6939
Epoch 2/20
146/146 [==============================] - 5s 33ms/step - loss: 0.5906 - accuracy: 0.6754 - val_loss: 0.5471 - val_accuracy: 0.7137
Epoch 3/20
146/146 [==============================] - 5s 33ms/step - loss: 0.5669 - accuracy: 0.7074 - val_loss: 0.5228 - val_accuracy: 0.7343
Epoch 4/20
146/146 [==============================] - 5s 33ms/step - loss: 0.5437 - accuracy: 0.7218 - val_loss: 0.4993 - val_accuracy: 0.7498
Epoch 5/20
146/146 [==============================] - 5s 33ms/step - loss: 0.5276 - accuracy: 0.7357 - val_loss: 0.4909 - val_accuracy: 0.7648
Epoch 6/20
146/146 [==============================] - 5s 33ms/step - loss: 0.5072 - accuracy: 0.7497 - val_loss: 0.4865 - val_accuracy: 0.7644
Epoch 7/20
146/146 [==============================] - 5s 33ms/step - loss: 0.4982 - accuracy: 0.7550 - val_loss: 0.4784 - val_accuracy: 0.7756
Epoch 8/20
146/146 [==============================] - 5s 33ms/step - loss: 0.4895 - accuracy: 0.7607 - val_loss: 0.4581 - val_accuracy: 0.7868
Epoch 9/20
146/146 [==============================] - 5s 33ms/step - loss: 0.4635 - accuracy: 0.7793 - val_loss: 0.4466 - val_accuracy: 0.7923
Epoch 10/20
146/146 [==============================] - 5s 33ms/step - loss: 0.4561 - accuracy: 0.7800 - val_loss: 0.4671 - val_accuracy: 0.7846
Epoch 11/20
146/146 [==============================] - 5s 33ms/step - loss: 0.4526 - accuracy: 0.7845 - val_loss: 0.4438 - val_accuracy: 0.7966
Epoch 12/20
146/146 [==============================] - 5s 33ms/step - loss: 0.4380 - accuracy: 0.7969 - val_loss: 0.4349 - val_accuracy: 0.7945
Epoch 13/20
146/146 [==============================] - 5s 33ms/step - loss: 0.4258 - accuracy: 0.8042 - val_loss: 0.4360 - val_accuracy: 0.8035
Epoch 14/20
146/146 [==============================] - 5s 33ms/step - loss: 0.4108 - accuracy: 0.8147 - val_loss: 0.4332 - val_accuracy: 0.8040
Epoch 15/20
146/146 [==============================] - 5s 34ms/step - loss: 0.4072 - accuracy: 0.8124 - val_loss: 0.4180 - val_accuracy: 0.7992
Epoch 16/20
146/146 [==============================] - 5s 35ms/step - loss: 0.4084 - accuracy: 0.8093 - val_loss: 0.4230 - val_accuracy: 0.7988
Epoch 17/20
146/146 [==============================] - 6s 39ms/step - loss: 0.4014 - accuracy: 0.8113 - val_loss: 0.4061 - val_accuracy: 0.8156
Epoch 18/20
146/146 [==============================] - 5s 33ms/step - loss: 0.3869 - accuracy: 0.8267 - val_loss: 0.4176 - val_accuracy: 0.8108
Epoch 19/20
146/146 [==============================] - 5s 33ms/step - loss: 0.3886 - accuracy: 0.8224 - val_loss: 0.3914 - val_accuracy: 0.8242
Epoch 20/20
146/146 [==============================] - 5s 33ms/step - loss: 0.3789 - accuracy: 0.8247 - val_loss: 0.3868 - val_accuracy: 0.8233</code></pre>
</div>
</div>
<p>We plot the training and validation accuracies:</p>
<div id="cell-53" class="cell" data-outputid="df88c402-5b84-413c-8625-b415e17849d7" data-execution_count="33">
<div class="sourceCode cell-code" id="cb32"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb32-1"><a href="#cb32-1" aria-hidden="true" tabindex="-1"></a>plt.plot(history.history[<span class="st">"accuracy"</span>], label <span class="op">=</span> <span class="st">"training"</span>)</span>
<span id="cb32-2"><a href="#cb32-2" aria-hidden="true" tabindex="-1"></a>plt.plot(history.history[<span class="st">"val_accuracy"</span>], label <span class="op">=</span> <span class="st">"validation"</span>)</span>
<span id="cb32-3"><a href="#cb32-3" aria-hidden="true" tabindex="-1"></a>plt.gca().<span class="bu">set</span>(xlabel <span class="op">=</span> <span class="st">"epoch"</span>, ylabel <span class="op">=</span> <span class="st">"accuracy"</span>)</span>
<span id="cb32-4"><a href="#cb32-4" aria-hidden="true" tabindex="-1"></a>plt.legend()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="ClassificationDogCat (1)_files/figure-html/cell-24-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<section id="comments-2" class="level2">
<h2 class="anchored" data-anchor-id="comments-2">Comments</h2>
<ul>
<li>The accuracy of our model is between <strong>around 80 to 82 percent</strong>.</li>
<li>The accuracy of <code>model3</code> is much higher than <code>model1</code>. In fact, it is around 30 percent better which is a very signficant difference in accuracy</li>
<li>There does not appear to be overfitting as the validation error is just slightly worse than the training error.</li>
</ul>
</section>
</section>
<section id="model-four-transfer-learning" class="level1">
<h1>5. Model Four: Transfer Learning</h1>
<p>In our final model, we use a pre-existing model that somebody else has created which has already learned relevant patterns. We incorporate this model into a full model for our task. The following code is from <code>MobileNetV2</code> that we will use to see if it improves our model! This is what we call <em>transfer learning</em>.</p>
<div id="cell-57" class="cell" data-outputid="30851f2c-eb51-4b63-cbef-666fa4d33b43" data-execution_count="34">
<div class="sourceCode cell-code" id="cb33"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb33-1"><a href="#cb33-1" aria-hidden="true" tabindex="-1"></a>IMG_SHAPE <span class="op">=</span> (<span class="dv">150</span>, <span class="dv">150</span>, <span class="dv">3</span>)</span>
<span id="cb33-2"><a href="#cb33-2" aria-hidden="true" tabindex="-1"></a>base_model <span class="op">=</span> keras.applications.MobileNetV3Large(input_shape<span class="op">=</span>IMG_SHAPE,</span>
<span id="cb33-3"><a href="#cb33-3" aria-hidden="true" tabindex="-1"></a>                                               include_top<span class="op">=</span><span class="va">False</span>,</span>
<span id="cb33-4"><a href="#cb33-4" aria-hidden="true" tabindex="-1"></a>                                               weights<span class="op">=</span><span class="st">'imagenet'</span>)</span>
<span id="cb33-5"><a href="#cb33-5" aria-hidden="true" tabindex="-1"></a>base_model.trainable <span class="op">=</span> <span class="va">False</span></span>
<span id="cb33-6"><a href="#cb33-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-7"><a href="#cb33-7" aria-hidden="true" tabindex="-1"></a>i <span class="op">=</span> keras.Input(shape<span class="op">=</span>IMG_SHAPE)</span>
<span id="cb33-8"><a href="#cb33-8" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> base_model(i, training <span class="op">=</span> <span class="va">False</span>)</span>
<span id="cb33-9"><a href="#cb33-9" aria-hidden="true" tabindex="-1"></a>base_model_layer <span class="op">=</span> keras.Model(inputs <span class="op">=</span> i, outputs <span class="op">=</span> x)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not 224. Weights for input shape (224, 224) will be loaded as the default.</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v3/weights_mobilenet_v3_large_224_1.0_float_no_top_v2.h5
12683000/12683000 [==============================] - 0s 0us/step</code></pre>
</div>
</div>
<p>Now we add <code>base_model_layer</code> to our own model. We use <code>GlobalMaxPooling2D</code>, a <code>Dropout</code> layer with 0.1, and a <code>Dense</code> layer of 80 output nodes for more learning just before our final output layer to increase accuracy.</p>
<div id="cell-59" class="cell" data-execution_count="35">
<div class="sourceCode cell-code" id="cb36"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb36-1"><a href="#cb36-1" aria-hidden="true" tabindex="-1"></a>model4 <span class="op">=</span> models.Sequential([</span>
<span id="cb36-2"><a href="#cb36-2" aria-hidden="true" tabindex="-1"></a>    data_augmentation,</span>
<span id="cb36-3"><a href="#cb36-3" aria-hidden="true" tabindex="-1"></a>    base_model_layer,</span>
<span id="cb36-4"><a href="#cb36-4" aria-hidden="true" tabindex="-1"></a>    layers.GlobalMaxPooling2D(),</span>
<span id="cb36-5"><a href="#cb36-5" aria-hidden="true" tabindex="-1"></a>    layers.Dropout(<span class="fl">.1</span>),</span>
<span id="cb36-6"><a href="#cb36-6" aria-hidden="true" tabindex="-1"></a>    layers.Dense(<span class="dv">80</span>, activation <span class="op">=</span> <span class="st">'relu'</span>),</span>
<span id="cb36-7"><a href="#cb36-7" aria-hidden="true" tabindex="-1"></a>    layers.Dense(<span class="dv">2</span>)</span>
<span id="cb36-8"><a href="#cb36-8" aria-hidden="true" tabindex="-1"></a>])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>We run <code>model4</code> summary.</p>
<div id="cell-61" class="cell" data-outputid="329665a1-b073-4d04-93ea-45df18171267" data-execution_count="36">
<div class="sourceCode cell-code" id="cb37"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb37-1"><a href="#cb37-1" aria-hidden="true" tabindex="-1"></a>model4.summary()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Model: "sequential_6"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 sequential_3 (Sequential)   (None, 150, 150, 3)       0         
                                                                 
 model_1 (Functional)        (None, 5, 5, 960)         2996352   
                                                                 
 global_max_pooling2d (Glob  (None, 960)               0         
 alMaxPooling2D)                                                 
                                                                 
 dropout_3 (Dropout)         (None, 960)               0         
                                                                 
 dense_6 (Dense)             (None, 80)                76880     
                                                                 
 dense_7 (Dense)             (None, 2)                 162       
                                                                 
=================================================================
Total params: 3073394 (11.72 MB)
Trainable params: 77042 (300.95 KB)
Non-trainable params: 2996352 (11.43 MB)
_________________________________________________________________</code></pre>
</div>
</div>
<p>We train our model.</p>
<div id="cell-63" class="cell" data-outputid="f66ee5d7-3e6c-4e05-d1c5-f8007ba88562" data-execution_count="37">
<div class="sourceCode cell-code" id="cb39"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb39-1"><a href="#cb39-1" aria-hidden="true" tabindex="-1"></a>model4.<span class="bu">compile</span>(optimizer<span class="op">=</span><span class="st">'adam'</span>,</span>
<span id="cb39-2"><a href="#cb39-2" aria-hidden="true" tabindex="-1"></a>              loss <span class="op">=</span> tf.keras.losses.SparseCategoricalCrossentropy(from_logits<span class="op">=</span><span class="va">True</span>),</span>
<span id="cb39-3"><a href="#cb39-3" aria-hidden="true" tabindex="-1"></a>              metrics <span class="op">=</span> [<span class="st">'accuracy'</span>])</span>
<span id="cb39-4"><a href="#cb39-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-5"><a href="#cb39-5" aria-hidden="true" tabindex="-1"></a>history <span class="op">=</span> model4.fit(train_ds,</span>
<span id="cb39-6"><a href="#cb39-6" aria-hidden="true" tabindex="-1"></a>                     epochs<span class="op">=</span><span class="dv">20</span>,</span>
<span id="cb39-7"><a href="#cb39-7" aria-hidden="true" tabindex="-1"></a>                     validation_data<span class="op">=</span>validation_ds)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Epoch 1/20
146/146 [==============================] - 16s 67ms/step - loss: 0.7214 - accuracy: 0.8909 - val_loss: 0.1005 - val_accuracy: 0.9635
Epoch 2/20
146/146 [==============================] - 6s 43ms/step - loss: 0.1847 - accuracy: 0.9320 - val_loss: 0.0829 - val_accuracy: 0.9682
Epoch 3/20
146/146 [==============================] - 6s 42ms/step - loss: 0.1521 - accuracy: 0.9426 - val_loss: 0.0721 - val_accuracy: 0.9746
Epoch 4/20
146/146 [==============================] - 6s 42ms/step - loss: 0.1393 - accuracy: 0.9465 - val_loss: 0.0678 - val_accuracy: 0.9755
Epoch 5/20
146/146 [==============================] - 6s 43ms/step - loss: 0.1182 - accuracy: 0.9519 - val_loss: 0.0843 - val_accuracy: 0.9686
Epoch 6/20
146/146 [==============================] - 6s 43ms/step - loss: 0.1173 - accuracy: 0.9542 - val_loss: 0.0702 - val_accuracy: 0.9742
Epoch 7/20
146/146 [==============================] - 6s 42ms/step - loss: 0.1087 - accuracy: 0.9585 - val_loss: 0.0634 - val_accuracy: 0.9785
Epoch 8/20
146/146 [==============================] - 6s 43ms/step - loss: 0.1052 - accuracy: 0.9585 - val_loss: 0.0617 - val_accuracy: 0.9764
Epoch 9/20
146/146 [==============================] - 6s 42ms/step - loss: 0.1130 - accuracy: 0.9551 - val_loss: 0.0582 - val_accuracy: 0.9789
Epoch 10/20
146/146 [==============================] - 6s 43ms/step - loss: 0.1008 - accuracy: 0.9572 - val_loss: 0.0767 - val_accuracy: 0.9716
Epoch 11/20
146/146 [==============================] - 6s 42ms/step - loss: 0.1020 - accuracy: 0.9582 - val_loss: 0.0624 - val_accuracy: 0.9746
Epoch 12/20
146/146 [==============================] - 6s 43ms/step - loss: 0.1038 - accuracy: 0.9570 - val_loss: 0.0571 - val_accuracy: 0.9772
Epoch 13/20
146/146 [==============================] - 6s 43ms/step - loss: 0.0974 - accuracy: 0.9606 - val_loss: 0.0631 - val_accuracy: 0.9755
Epoch 14/20
146/146 [==============================] - 6s 42ms/step - loss: 0.0930 - accuracy: 0.9616 - val_loss: 0.0589 - val_accuracy: 0.9776
Epoch 15/20
146/146 [==============================] - 6s 43ms/step - loss: 0.0922 - accuracy: 0.9629 - val_loss: 0.0608 - val_accuracy: 0.9772
Epoch 16/20
146/146 [==============================] - 6s 43ms/step - loss: 0.0820 - accuracy: 0.9667 - val_loss: 0.0622 - val_accuracy: 0.9742
Epoch 17/20
146/146 [==============================] - 7s 47ms/step - loss: 0.0839 - accuracy: 0.9660 - val_loss: 0.0691 - val_accuracy: 0.9733
Epoch 18/20
146/146 [==============================] - 7s 45ms/step - loss: 0.0870 - accuracy: 0.9650 - val_loss: 0.0626 - val_accuracy: 0.9781
Epoch 19/20
146/146 [==============================] - 6s 42ms/step - loss: 0.0783 - accuracy: 0.9681 - val_loss: 0.0637 - val_accuracy: 0.9742
Epoch 20/20
146/146 [==============================] - 6s 43ms/step - loss: 0.0855 - accuracy: 0.9688 - val_loss: 0.0742 - val_accuracy: 0.9716</code></pre>
</div>
</div>
<p>Finally, we plot our validation and training accuracies.</p>
<div id="cell-65" class="cell" data-outputid="fc92b893-a0e8-4f68-91ca-6517fefed5e7" data-execution_count="38">
<div class="sourceCode cell-code" id="cb41"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb41-1"><a href="#cb41-1" aria-hidden="true" tabindex="-1"></a>plt.plot(history.history[<span class="st">"accuracy"</span>], label <span class="op">=</span> <span class="st">"training"</span>)</span>
<span id="cb41-2"><a href="#cb41-2" aria-hidden="true" tabindex="-1"></a>plt.plot(history.history[<span class="st">"val_accuracy"</span>], label <span class="op">=</span> <span class="st">"validation"</span>)</span>
<span id="cb41-3"><a href="#cb41-3" aria-hidden="true" tabindex="-1"></a>plt.gca().<span class="bu">set</span>(xlabel <span class="op">=</span> <span class="st">"epoch"</span>, ylabel <span class="op">=</span> <span class="st">"accuracy"</span>)</span>
<span id="cb41-4"><a href="#cb41-4" aria-hidden="true" tabindex="-1"></a>plt.legend()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="ClassificationDogCat (1)_files/figure-html/cell-29-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<section id="comments-3" class="level2">
<h2 class="anchored" data-anchor-id="comments-3">Comments</h2>
<ul>
<li>The accuracy of our model stabilizes around <strong>96 to 97</strong> percent</li>
<li>This accuracy is significantly better than <code>model1</code> and all the other models which we have tested</li>
<li>No overfitting issues seem to be present as our validation error actually outperforms our training error by one percent!</li>
</ul>
</section>
</section>
<section id="final-score-on-best-model" class="level1">
<h1>6. Final Score on Best Model</h1>
<p>Now it is time to access our best model on the testing dataset which we left to the side at the start of this blog.</p>
<div id="cell-69" class="cell" data-outputid="2eddb343-a3e3-4a26-ec12-1c3e519f5822" data-execution_count="39">
<div class="sourceCode cell-code" id="cb42"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb42-1"><a href="#cb42-1" aria-hidden="true" tabindex="-1"></a>model4.evaluate(test_ds, verbose<span class="op">=</span><span class="dv">1</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>37/37 [==============================] - 4s 92ms/step - loss: 0.1106 - accuracy: 0.9609</code></pre>
</div>
<div class="cell-output cell-output-display" data-execution_count="39">
<pre><code>[0.11059626936912537, 0.9608770608901978]</code></pre>
</div>
</div>
<p>The accuracy is <strong>96.09</strong> percent which is very very good! This means that out of 100 images, our model correctly predicts whether it is a dog or a cat 96 times. Incredible!</p>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      return note.innerHTML;
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->




</body></html>